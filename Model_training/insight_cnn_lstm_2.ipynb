{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "insight_cnn_lstm_2.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB4G-JBcxbfA",
        "colab_type": "code",
        "outputId": "100e03b8-dbd1-48c0-c9bd-8c757ea7e39c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        }
      },
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pylab as plt\n",
        "from PIL import Image\n",
        "import matplotlib\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import keras\n",
        "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, TensorBoard\n",
        "from keras import optimizers\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dropout, UpSampling2D, BatchNormalization, Activation, Dense, Lambda, TimeDistributed, Flatten\n",
        "from keras.layers import LSTM, GRU, RNN, Reshape, CuDNNGRU, CuDNNLSTM\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D, MaxPooling3D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv3D\n",
        "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
        "from keras import backend as K\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import Callback\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import tensorflow as tf\n",
        "import gc\n",
        "from keras import layers, models, applications\n",
        "from keras.layers import concatenate\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras import layers, models, applications\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "from keras.backend.tensorflow_backend import set_session\n",
        "from keras.backend.tensorflow_backend import clear_session\n",
        "from keras.backend.tensorflow_backend import get_session\n",
        "import tensorflow\n",
        "# Reset Keras Session\n",
        "def reset_keras():\n",
        "    sess = get_session()\n",
        "    clear_session()\n",
        "    sess.close()\n",
        "    sess = get_session()\n",
        "    try:\n",
        "        del classifier # this is from global space - change this as you need\n",
        "    except:\n",
        "        pass\n",
        "    print(gc.collect()) # if it's done something you should see a number being outputted\n",
        "\n",
        "    # use the same config as you used to create the session\n",
        "    config = tensorflow.ConfigProto()\n",
        "    config.gpu_options.per_process_gpu_memory_fraction = 1\n",
        "    config.gpu_options.visible_device_list = \"0\"\n",
        "    set_session(tensorflow.Session(config=config))\n",
        "\n",
        "def random_everything(seed=42):\n",
        "  os.environ['PYTHONHASHSEED'] = str(42)\n",
        "  random.seed(42)\n",
        "  np.random.seed(42)\n",
        "  tf.set_random_seed(42)\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "def f2_m(y_true, y_pred, beta=2):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return (1+beta**2) * (precision*recall) / ((beta**2)*(precision)+recall+K.epsilon())\n",
        "\n",
        "def f3_m(y_true, y_pred, beta=3):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return (1+beta**2) * (precision*recall) / ((beta**2)*(precision)+recall+K.epsilon())\n",
        "\n",
        "def f4_m(y_true, y_pred, beta=4):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return (1+beta**2) * (precision*recall) / ((beta**2)*(precision)+recall+K.epsilon())\n",
        "\n",
        "'''\n",
        "a = []\n",
        "while(1):\n",
        "  a.append('1')\n",
        "'''\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\na = []\\nwhile(1):\\n  a.append('1')\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H08heUDbxedd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ConvBlock(inputs, suffix=0, prefix=\"cnn\"):\n",
        "    \"\"\"no final linear dense layer!\"\"\"\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name=f\"{prefix}_{suffix}_conv_1a\")(inputs)\n",
        "    conv1 = BatchNormalization(name=f\"{prefix}_{suffix}_batchnorm_1a\")(conv1)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name=f\"{prefix}_{suffix}_conv_1b\")(conv1)\n",
        "    conv1 = BatchNormalization(name=f\"{prefix}_{suffix}_batchnorm_1b\")(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2), name=f\"{prefix}_{suffix}_maxpool_1\")(conv1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name=f\"{prefix}_{suffix}_conv_2a\")(pool1)\n",
        "    conv2 = BatchNormalization(name=f\"{prefix}_{suffix}_batchnorm_2a\")(conv2)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name=f\"{prefix}_{suffix}_conv_2b\")(conv2)\n",
        "    conv2 = BatchNormalization(name=f\"{prefix}_{suffix}_batchnorm_2b\")(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2), name=f\"index_{suffix}_maxpool_2\")(conv2)\n",
        "    \n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name=f\"{prefix}_{suffix}_conv_3a\")(pool2)\n",
        "    conv3 = BatchNormalization(name=f\"{prefix}_{suffix}_batchnorm_3a\")(conv3)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name=f\"{prefix}_{suffix}_conv_3b\")(conv3)\n",
        "    conv3 = BatchNormalization(name=f\"{prefix}_{suffix}_batchnorm_3b\")(conv3)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name=f\"{prefix}_{suffix}_conv_3c\")(conv3)\n",
        "    conv3 = BatchNormalization(name=f\"{prefix}_{suffix}_batchnorm_3c\")(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2), name=f\"index_{suffix}_maxpool_3\")(conv3)\n",
        "\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name=f\"{prefix}_{suffix}_conv_4a\")(pool3)\n",
        "    conv4 = BatchNormalization(name=f\"{prefix}_{suffix}_batchnorm_4a\")(conv4)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name=f\"{prefix}_{suffix}_conv_4b\")(conv4)\n",
        "    conv4 = BatchNormalization(name=f\"{prefix}_{suffix}_batchnorm_4b\")(conv4)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name=f\"{prefix}_{suffix}_conv_4c\")(conv4)\n",
        "    conv4 = BatchNormalization(name=f\"{prefix}_{suffix}_batchnorm_4c\")(conv4)    \n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2), name=f\"{prefix}_{suffix}_maxpool_4\")(conv4)    \n",
        "\n",
        "    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name=f\"{prefix}_{suffix}_conv_5a\")(pool4)\n",
        "    conv5 = BatchNormalization(name=f\"{prefix}_{suffix}_batchnorm_5a\")(conv5)\n",
        "    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name=f\"{prefix}_{suffix}_conv_5b\")(conv5)\n",
        "    conv5 = BatchNormalization(name=f\"{prefix}_{suffix}_batchnorm_5b\")(conv5)\n",
        "    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name=f\"{prefix}_{suffix}_conv_5c\")(conv5)\n",
        "    conv5 = BatchNormalization(name=f\"{prefix}_{suffix}_batchnorm_5c\")(conv5)    \n",
        "    pool5 = MaxPooling2D(pool_size=(2, 2), name=f\"{prefix}_{suffix}_maxpool_5\")(conv5)   \n",
        "    \n",
        "    flatten= Flatten(name=f\"{prefix}_{suffix}_flatten\")(pool5)\n",
        "    dense1 = Dense(512, activation=\"relu\", name=f\"{prefix}_{suffix}_relu_1\")(flatten)\n",
        "    drop1  = Dropout(0.4, name=f\"{prefix}_{suffix}_drop_1\")(dense1)\n",
        "    dense2 = Dense(128, activation=\"relu\", name=f\"{prefix}_{suffix}_relu_2\")(drop1)\n",
        "    drop2  = Dropout(0.3, name=f\"{prefix}_{suffix}_drop_2\")(dense2)\n",
        "    dense3 = Dense(32, activation=\"relu\", name=f\"{prefix}_{suffix}_relu_3\")(drop2)\n",
        "    drop3  = Dropout(0.2, name=f\"{prefix}_{suffix}_drop_3\")(dense3)\n",
        "    dense4 = Dense(8, activation=\"relu\",  name=f\"{prefix}_{suffix}_relu_4\")(drop3)\n",
        "    return dense4\n",
        "\n",
        "def MLP(inputs, suffix=0, prefix='mlp'):\n",
        "    dense = Dense(8, activation='relu', name=f\"{prefix}_{suffix}_relu_1\")(inputs)\n",
        "    dense = Dense(4, activation='relu', name=f\"{prefix}_{suffix}_relu_2\")(dense)\n",
        "    return dense\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLbhVPbAxgtW",
        "colab_type": "code",
        "outputId": "b50e1612-8e5d-4f59-9a2a-a5cc9ab9c408",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        }
      },
      "source": [
        "n_channels = 14\n",
        "sector_dim = 200\n",
        "\n",
        "img_0 = Input((sector_dim,sector_dim,n_channels), name=\"cnn_input_0\")\n",
        "img_1 = Input((sector_dim,sector_dim,n_channels), name=\"cnn_input_1\")\n",
        "img_2 = Input((sector_dim,sector_dim,n_channels), name=\"cnn_input_2\")\n",
        "\n",
        "num_0 = Input((50,), name=\"gsod_input_0\")\n",
        "num_1 = Input((50,), name=\"gsod_input_1\")\n",
        "num_2 = Input((10,), name=\"gsod_input_2\")\n",
        "\n",
        "adj_0 = Input((8,), name=\"adj_input_0\")\n",
        "adj_1 = Input((8,), name=\"adj_input_1\")\n",
        "adj_2 = Input((8,), name=\"adj_input_2\")\n",
        "\n",
        "cnn_0 = ConvBlock(img_0, suffix=0)\n",
        "cnn_1 = ConvBlock(img_1, suffix=1)\n",
        "cnn_2 = ConvBlock(img_2, suffix=2)\n",
        "\n",
        "num_0_m = MLP(num_0, suffix=0, prefix=\"gsod\")\n",
        "num_1_m = MLP(num_1, suffix=1, prefix=\"gsod\")\n",
        "num_2_m = MLP(num_2, suffix=2, prefix=\"gsod\")\n",
        "\n",
        "adj_0_m = MLP(adj_0, suffix=0, prefix=\"adj\")\n",
        "adj_1_m = MLP(adj_1, suffix=1, prefix=\"adj\")\n",
        "adj_2_m = MLP(adj_2, suffix=2, prefix=\"adj\")\n",
        "\n",
        "mixed_0 = concatenate([cnn_0, num_0_m, adj_0_m], name='mixed_0')\n",
        "mixed_1 = concatenate([cnn_1, num_1_m, adj_1_m], name='mixed_1')\n",
        "mixed_2 = concatenate([cnn_2, num_2_m, adj_2_m], name='mixed_2')\n",
        "\n",
        "concat   = concatenate([mixed_0, mixed_1, mixed_2], name=\"concat_mixed\")\n",
        "reshape  = Reshape((3, -1), name=\"reshape\")(concat)\n",
        "lstm     = LSTM(256, name='lstm_1', return_sequences=True)(reshape)\n",
        "lstm     = Dropout(0.4, name='lstm_drop_1')(lstm)\n",
        "lstm     = LSTM(256, name='lstm_2')(lstm)\n",
        "lstm     = Dropout(0.4, name='lstm_drop_2')(lstm)\n",
        "dense    = Dense(10, activation=\"relu\", name=\"fc_relu\")(lstm)\n",
        "dense    = Dense(1, activation=\"sigmoid\", name=\"fc_sigmoid\")(dense)\n",
        "\n",
        "model = Model(inputs=[img_0, img_1, img_2, num_0, num_1, num_2, adj_0, adj_1, adj_2], output=dense)\n",
        "#model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"fc...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkFaftIhxiPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Data(object):\n",
        "    def __init__(self, imgs, labs, zone_idx=np.arange(20), size=108):\n",
        "        self.imgs = imgs\n",
        "        self.labs = labs\n",
        "        self.size = size\n",
        "        self.zone_idx = zone_idx\n",
        "\n",
        "    def extract_single_zone(self, imgs, labs, idx=0):\n",
        "        \"\"\"extract a single zone based on the index\"\"\"\n",
        "        assert idx >= 0 and idx <= 24\n",
        "        try:\n",
        "            assert len(imgs) == self.size\n",
        "        except Exception:\n",
        "            imgs = imgs[:self.size,:]     ## if there are more images than labels, cut the images to approporiate size!\n",
        "        try:\n",
        "            assert len(labs) == self.size\n",
        "        except Exception:\n",
        "            labs = labs[:self.size,:]     \n",
        "\n",
        "        row_idx = idx//5\n",
        "        col_idx = idx%5\n",
        "        return imgs[:, row_idx*200:(row_idx+1)*200, col_idx*200:(col_idx+1)*200, :], labs[:, row_idx*200:(row_idx+1)*200, col_idx*200:(col_idx+1)*200, :]\n",
        "   \n",
        "    def burn_ratio(self, labs):\n",
        "        \"\"\"calculate the burn ratio in an area\"\"\"\n",
        "        ratio = np.zeros((labs.shape[0],))\n",
        "        for i in range(len(labs)):\n",
        "          ratio[i] = labs[i,:,:,:].mean()\n",
        "        return ratio\n",
        "\n",
        "    def binarize_risk(self, labs, thres=0.05):\n",
        "        #ratio = labs.sum(axis=-1).sum(axis=-1).sum(axis=-1)/(200*200)\n",
        "        ratio = self.burn_ratio(labs)\n",
        "        return (ratio>thres).astype(int)\n",
        "\n",
        "    def compile_zones(self):\n",
        "        \"\"\"concatenate all sector images based on selected index\"\"\"\n",
        "        \"\"\"Zone 0,0,0,0,0,0,0,0,0 .... Zone 1,1,1,1....\"\"\"\n",
        "        \"\"\"Normalize to (0, 1) !!!\"\"\"\n",
        "        imgs, labs = self.extract_single_zone(self.imgs, self.labs, idx=self.zone_idx[0])\n",
        "        for i in range(1, len(self.zone_idx)):\n",
        "            I, L = self.extract_single_zone(self.imgs, self.labs, idx=self.zone_idx[i])\n",
        "            imgs = np.concatenate([imgs, I], 0)\n",
        "            labs = np.concatenate([labs, L], 0)\n",
        "        imgs = imgs/imgs.max()\n",
        "        imgs = imgs.astype('float32')\n",
        "        return imgs, labs\n",
        "        \n",
        "    def prepare_step_data(self):\n",
        "        zoned_imgs, zoned_labs = self.compile_zones()\n",
        "        idx = np.array([i for i in range(len(zoned_imgs)) if i % self.size not in [self.size-2, self.size-1, self.size]])\n",
        "        imgs_0 = zoned_imgs[idx, :,:,:]\n",
        "        imgs_1 = zoned_imgs[idx+1, :,:,:]\n",
        "        imgs_2, labs = zoned_imgs[idx+2, :,:,:], self.binarize_risk(zoned_labs[idx+2])\n",
        "        return imgs_0, imgs_1, imgs_2, labs\n",
        "\n",
        "\n",
        "class Adjacency(object):\n",
        "    \"\"\"Only to extract burn ratio from label, no images, no binarized labels, burn ratio is the feature to extract\"\"\"\n",
        "    def __init__(self, labs, zone_idx=np.arange(20), size=108):\n",
        "        self.labs = labs\n",
        "        self.size = size\n",
        "        self.zone_idx = zone_idx\n",
        "    \n",
        "    def extract_single_zone(self, labs, idx=0):\n",
        "        \"\"\"extract a single zone based on the index\"\"\"\n",
        "        assert idx >= 0 and idx <= 24\n",
        "        try:\n",
        "            assert len(labs) == self.size\n",
        "        except Exception:\n",
        "            labs = labs[:self.size,:]     \n",
        "        row_idx = idx//5\n",
        "        col_idx = idx%5\n",
        "        return labs[:, row_idx*200:(row_idx+1)*200, col_idx*200:(col_idx+1)*200, :]\n",
        "\n",
        "    def burn_ratio(self,labs):\n",
        "        \"\"\"calculate the burn ratio in an area\"\"\"\n",
        "        ratio = np.zeros((labs.shape[0],))\n",
        "        for i in range(len(labs)):\n",
        "          ratio[i] = labs[i,:,:,:].mean()\n",
        "        return ratio\n",
        "    \n",
        "    def binarize_risk(self,labs, thres=0.05):\n",
        "        ratio = labs.sum(axis=-1).sum(axis=-1).sum(axis=-1)/(200*200)\n",
        "        return (ratio>thres).astype(int)\n",
        "\n",
        "    def compile_zones(self):\n",
        "        \"\"\"concatenate all sector images based on selected index\"\"\"\n",
        "        \"\"\"Zone 0,0,0,0,0,0,0,0,0 .... Zone 1,1,1,1....\"\"\"\n",
        "        \"\"\"Normalize to (0, 1) !!!\"\"\"\n",
        "        labs = self.extract_single_zone(self.labs, idx=self.zone_idx[0])\n",
        "        for i in range(1, len(self.zone_idx)):\n",
        "            L = self.extract_single_zone(self.labs, idx=self.zone_idx[i])\n",
        "            labs = np.concatenate([labs, L], 0)\n",
        "        return labs\n",
        "\n",
        "    def prepare_step_data(self):\n",
        "        zoned_labs = self.compile_zones()\n",
        "        idx = np.array([i for i in range(len(zoned_labs)) if i % self.size not in [self.size-2, self.size-1, self.size]])\n",
        "        adj_0 = self.burn_ratio(zoned_labs[idx])\n",
        "        adj_1 = self.burn_ratio(zoned_labs[idx+1])\n",
        "        adj_2 = self.burn_ratio(zoned_labs[idx+2])\n",
        "        return adj_0, adj_1, adj_2\n",
        "\n",
        "def extract_adjacency_feature(indices, mode='trn_val'):\n",
        "    \"\"\"\n",
        "    Function to extract adjacency features\n",
        "    indices must be in list format,\n",
        "    mode can be either trn_val or test\n",
        "    \"\"\"\n",
        "    names = ['south','southwest','west','northwest','north','northeast','east','southeast']\n",
        "    \n",
        "    def subset_adjacency(which=0):\n",
        "        \"\"\"Extract adjacency feature based on 1 direction\"\"\"\n",
        "        name = names[which]\n",
        "        row = 200\n",
        "        col = 200\n",
        "        if 'south' in name:\n",
        "            row = 400\n",
        "        elif 'north' in name:\n",
        "            row = 0\n",
        "        if 'west' in name:\n",
        "            col = 0\n",
        "        elif 'east' in name:\n",
        "            col = 400\n",
        "        return adjacency_full[:,row:row+1000,col:col+1000,:]\n",
        "    \n",
        "    if mode == 'trn_val':\n",
        "        trn_adj_0_list = []\n",
        "        trn_adj_1_list = []\n",
        "        trn_adj_2_list = []\n",
        "    \n",
        "        val_adj_0_list = []\n",
        "        val_adj_1_list = []\n",
        "        val_adj_2_list = []\n",
        "\n",
        "        trn_idx = indices[0]\n",
        "        val_idx = indices[1]\n",
        "        for i in tqdm_notebook(range(8)):\n",
        "            adjacency_full = np.load('/content/gdrive/My Drive/adjacency.npz')['dnbr']\n",
        "            adjacency = subset_adjacency(which=i)\n",
        "            \"\"\"binarize to burn or unburnt pixels\"\"\"\n",
        "            adjacency = (adjacency>0.66).astype(int)\n",
        "            \"\"\"Adjacency feature is always taken on timestep prior!!! This is to avoid data leakage!!!\"\"\"\n",
        "            adjacency = np.concatenate([np.zeros((1,1000,1000,1), dtype='int'), adjacency[:-1]],0)\n",
        "            del adjacency_full\n",
        "            gc.collect()\n",
        "            trn_data = Adjacency(adjacency, zone_idx=trn_idx)\n",
        "            val_data = Adjacency(adjacency, zone_idx=val_idx)\n",
        "            del adjacency\n",
        "            gc.collect()\n",
        "            trn_adj_0, trn_adj_1, trn_adj_2 = trn_data.prepare_step_data()\n",
        "            val_adj_0, val_adj_1, val_adj_2 = val_data.prepare_step_data()\n",
        "            del trn_data, val_data\n",
        "            gc.collect()\n",
        "            trn_adj_0_list.append(trn_adj_0)\n",
        "            trn_adj_1_list.append(trn_adj_1)\n",
        "            trn_adj_2_list.append(trn_adj_2)\n",
        "            val_adj_0_list.append(val_adj_0)\n",
        "            val_adj_1_list.append(val_adj_1)\n",
        "            val_adj_2_list.append(val_adj_2)\n",
        "\n",
        "        trn_adj_0_list = np.column_stack(trn_adj_0_list)\n",
        "        trn_adj_1_list = np.column_stack(trn_adj_1_list)\n",
        "        trn_adj_2_list = np.column_stack(trn_adj_2_list)\n",
        "        val_adj_0_list = np.column_stack(val_adj_0_list)\n",
        "        val_adj_1_list = np.column_stack(val_adj_1_list)\n",
        "        val_adj_2_list = np.column_stack(val_adj_2_list)\n",
        "\n",
        "        return trn_adj_0_list, trn_adj_1_list, trn_adj_2_list, val_adj_0_list, val_adj_1_list, val_adj_2_list\n",
        "\n",
        "    elif mode == 'test':\n",
        "        test_adj_0_list = []\n",
        "        test_adj_1_list = []\n",
        "        test_adj_2_list = []\n",
        "\n",
        "        test_idx = indices[0]\n",
        "        for i in tqdm_notebook(range(8)):\n",
        "            adjacency_full = np.load('/content/gdrive/My Drive/adjacency.npz')['dnbr']\n",
        "            adjacency = subset_adjacency(which=i)\n",
        "            adjacency = (adjacency>0.66).astype(int)\n",
        "            adjacency = np.concatenate([np.zeros((1,1000,1000,1), dtype='int'), adjacency[:-1]],0)\n",
        "            del adjacency_full\n",
        "            gc.collect()\n",
        "            test_data = Adjacency(adjacency, zone_idx=test_idx)\n",
        "            del adjacency\n",
        "            gc.collect()\n",
        "            test_adj_0, test_adj_1, test_adj_2 = test_data.prepare_step_data()\n",
        "            del test_data\n",
        "            gc.collect()\n",
        "            test_adj_0_list.append(test_adj_0)\n",
        "            test_adj_1_list.append(test_adj_1)\n",
        "            test_adj_2_list.append(test_adj_2)\n",
        "\n",
        "        test_adj_0_list = np.column_stack(test_adj_0_list)\n",
        "        test_adj_1_list = np.column_stack(test_adj_1_list)\n",
        "        test_adj_2_list = np.column_stack(test_adj_2_list)\n",
        "\n",
        "        return test_adj_0_list, test_adj_1_list, test_adj_2_list\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX5IMDLQxi46",
        "colab_type": "code",
        "outputId": "ec41e439-60cf-4e9e-ed93-8f20e07c5c84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "source": [
        "from google.colab import drive\n",
        "#drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "\n",
        "water_mask = np.load('/content/gdrive/My Drive/water_mask_based_on_ndvi_565.npy')\n",
        "water_mask = np.expand_dims(water_mask, 2)\n",
        "plt.imshow(water_mask[:,:,0], cmap='Greys_r')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8b99c297b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npOaMgNScEZCaMwJSc0ZAas4ISM39H6skPSAMIXjsAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfE62rnbxkk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "I = 2\n",
        "trn_idx = [i for i in range(25) if i not in range(5*I, 5*I+5)]\n",
        "val_idx = [i for i in range(25) if i in range(5*I, 5*I+5)]\n",
        "\n",
        "imgs = np.load('/content/gdrive/My Drive/cloud_control_data.npz')['imgs']\n",
        "dnbr = np.load('/content/gdrive/My Drive/adjacency.npz')['dnbr']\n",
        "dnbr = dnbr[:,200:1200,200:1200,:]\n",
        "\n",
        "labs = (dnbr>0.66).astype(int)\n",
        "del dnbr\n",
        "gc.collect()\n",
        "## apply water mask\n",
        "for i in range(len(labs)):\n",
        "    labs[i,:][water_mask==1] = 0\n",
        "\n",
        "trn_data = Data(imgs, labs, zone_idx=trn_idx)\n",
        "val_data = Data(imgs, labs, zone_idx=val_idx)\n",
        "\n",
        "del imgs, labs\n",
        "gc.collect()\n",
        "\n",
        "x_trn_0, x_trn_1, x_trn_2, y_trn = trn_data.prepare_step_data()\n",
        "x_val_0, x_val_1, x_val_2, y_val = val_data.prepare_step_data()\n",
        "\n",
        "del trn_data, val_data, water_mask\n",
        "gc.collect()\n",
        "\n",
        "try:\n",
        "    adj_trn_0 = np.load(f'/content/gdrive/My Drive/adjacency_features_{I}.npz')['adj_trn_0']\n",
        "    adj_trn_1 = np.load(f'/content/gdrive/My Drive/adjacency_features_{I}.npz')['adj_trn_1']\n",
        "    adj_trn_2 = np.load(f'/content/gdrive/My Drive/adjacency_features_{I}.npz')['adj_trn_2']\n",
        "\n",
        "    adj_val_0 = np.load(f'/content/gdrive/My Drive/adjacency_features_{I}.npz')['adj_val_0']\n",
        "    adj_val_1 = np.load(f'/content/gdrive/My Drive/adjacency_features_{I}.npz')['adj_val_1']\n",
        "    adj_val_2 = np.load(f'/content/gdrive/My Drive/adjacency_features_{I}.npz')['adj_val_2']\n",
        "\n",
        "except Exception:\n",
        "    adj_trn_0, adj_trn_1, adj_trn_2, adj_val_0, adj_val_1, adj_val_2 = extract_adjacency_feature([trn_idx, val_idx])\n",
        "    np.savez_compressed(f'/content/gdrive/My Drive/adjacency_features_{I}', adj_trn_0=adj_trn_0, adj_trn_1=adj_trn_1, adj_trn_2=adj_trn_2, adj_val_0=adj_val_0, adj_val_1=adj_val_1, adj_val_2=adj_val_2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0CqyGYWxmmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gsod = pd.read_csv('/content/gdrive/My Drive/flinders_chase_clean_5day.csv').values\n",
        "gsod = np.array(gsod, dtype='float')\n",
        "## normalize\n",
        "gsod = gsod/gsod.max(axis=0)\n",
        "\n",
        "num_trn_0, num_trn_1, num_trn_2 = gsod[:-2,:], gsod[1:-1,:], gsod[2:,:10]\n",
        "num_val_0, num_val_1, num_val_2 = gsod[:-2,:], gsod[1:-1,:], gsod[2:,:10]\n",
        "for i in range(len(trn_idx)-1):\n",
        "  num_trn_0 = np.concatenate([num_trn_0, gsod[:-2,:]])\n",
        "  num_trn_1 = np.concatenate([num_trn_1, gsod[1:-1,:]])\n",
        "  ### the last series should only have day_0 data!\n",
        "  num_trn_2 = np.concatenate([num_trn_2, gsod[2:,:10]])\n",
        "for i in range(len(val_idx)-1):\n",
        "  num_val_0 = np.concatenate([num_val_0, gsod[:-2,:]])\n",
        "  num_val_1 = np.concatenate([num_val_1, gsod[1:-1,:]])\n",
        "  ### the last series should only have day_0 data!\n",
        "  num_val_2 = np.concatenate([num_val_2, gsod[2:,:10]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPCcGirBxoLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_loss(y_true, y_pred, w=20):\n",
        "    crossentropy_loss = K.binary_crossentropy(y_true, y_pred)\n",
        "    weight  = (y_true*(w-1)) + 1\n",
        "    return crossentropy_loss*(weight)*(1/w)\n",
        "\n",
        "def f2_loss(y_true, y_pred, beta=2):\n",
        "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "    p = tp / (tp + fp + K.epsilon())\n",
        "    r = tp / (tp + fn + K.epsilon())\n",
        "    f_score = (1+beta**2) * p * r / ( (beta**2) * p + r + K.epsilon())\n",
        "    f_score = tf.where(tf.is_nan(f_score), tf.zeros_like(f_score), f_score)\n",
        "    return 1 - K.mean(f_score)\n",
        "\n",
        "def f4_loss(y_true, y_pred, beta=4):\n",
        "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "    p = tp / (tp + fp + K.epsilon())\n",
        "    r = tp / (tp + fn + K.epsilon())\n",
        "    f_score = (1+beta**2) * p * r / ( (beta**2) * p + r + K.epsilon())\n",
        "    f_score = tf.where(tf.is_nan(f_score), tf.zeros_like(f_score), f_score)\n",
        "    return 1 - K.mean(f_score)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "296gq-K3xo1s",
        "colab_type": "code",
        "outputId": "12ba5769-951c-47cc-a7c5-a08dc09c3c2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "random_everything(seed=42)\n",
        "#model = Model(inputs=[img_0, img_1, img_2, num_0, num_1, num_2, adj_0, adj_1, adj_2], output=dense)\n",
        "\n",
        "model.compile(optimizer = Adam(lr=2e-5, decay=1e-6), \n",
        "              #loss=custom_loss,\n",
        "              loss=f4_loss,\n",
        "              metrics=['acc', recall_m, precision_m, f1_m, f2_m, f3_m, f4_m])\n",
        "\n",
        "ckpt = ModelCheckpoint(f\"/content/gdrive/My Drive/CNN_LSTM_{I}_final.hdf5\", monitor = \"val_f4_m\", save_best_only = True, mode = \"max\", save_weights_only=True)\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "\n",
        "history = model.fit([x_trn_0, x_trn_1, x_trn_2, num_trn_0, num_trn_1, num_trn_2, adj_trn_0, adj_trn_1, adj_trn_2], y_trn,\n",
        "                        validation_data=([x_val_0, x_val_1, x_val_2, num_val_0, num_val_1, num_val_2, adj_val_0, adj_val_1, adj_val_2], y_val),\n",
        "                        batch_size=24, epochs=100,\n",
        "                        callbacks=[es, ckpt, \n",
        "                                   keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-8 )\n",
        "                                   ]\n",
        "                        )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-8-2b8940b291b0>:25: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 2120 samples, validate on 530 samples\n",
            "Epoch 1/100\n",
            "2120/2120 [==============================] - 100s 47ms/step - loss: 0.7449 - acc: 0.0500 - recall_m: 0.6802 - precision_m: 0.0455 - f1_m: 0.0843 - f2_m: 0.1735 - f3_m: 0.2711 - f4_m: 0.3559 - val_loss: 0.7877 - val_acc: 0.0358 - val_recall_m: 0.4981 - val_precision_m: 0.0358 - val_f1_m: 0.0661 - val_f2_m: 0.1348 - val_f3_m: 0.2081 - val_f4_m: 0.2704\n",
            "Epoch 2/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.7126 - acc: 0.0458 - recall_m: 0.6340 - precision_m: 0.0458 - f1_m: 0.0839 - f2_m: 0.1696 - f3_m: 0.2610 - f4_m: 0.3390 - val_loss: 0.7499 - val_acc: 0.0358 - val_recall_m: 0.4981 - val_precision_m: 0.0358 - val_f1_m: 0.0661 - val_f2_m: 0.1348 - val_f3_m: 0.2081 - val_f4_m: 0.2704\n",
            "Epoch 3/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.6557 - acc: 0.0458 - recall_m: 0.6943 - precision_m: 0.0458 - f1_m: 0.0847 - f2_m: 0.1744 - f3_m: 0.2731 - f4_m: 0.3593 - val_loss: 0.7301 - val_acc: 0.0358 - val_recall_m: 0.4981 - val_precision_m: 0.0358 - val_f1_m: 0.0661 - val_f2_m: 0.1348 - val_f3_m: 0.2081 - val_f4_m: 0.2704\n",
            "Epoch 4/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.6414 - acc: 0.0458 - recall_m: 0.6717 - precision_m: 0.0458 - f1_m: 0.0844 - f2_m: 0.1726 - f3_m: 0.2685 - f4_m: 0.3517 - val_loss: 0.7155 - val_acc: 0.0358 - val_recall_m: 0.4981 - val_precision_m: 0.0358 - val_f1_m: 0.0661 - val_f2_m: 0.1348 - val_f3_m: 0.2081 - val_f4_m: 0.2704\n",
            "Epoch 5/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.6243 - acc: 0.0476 - recall_m: 0.6717 - precision_m: 0.0458 - f1_m: 0.0845 - f2_m: 0.1731 - f3_m: 0.2697 - f4_m: 0.3533 - val_loss: 0.7119 - val_acc: 0.0358 - val_recall_m: 0.4981 - val_precision_m: 0.0358 - val_f1_m: 0.0661 - val_f2_m: 0.1348 - val_f3_m: 0.2081 - val_f4_m: 0.2704\n",
            "Epoch 6/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.6320 - acc: 0.0689 - recall_m: 0.6453 - precision_m: 0.0466 - f1_m: 0.0854 - f2_m: 0.1725 - f3_m: 0.2655 - f4_m: 0.3452 - val_loss: 0.7018 - val_acc: 0.3679 - val_recall_m: 0.4981 - val_precision_m: 0.0482 - val_f1_m: 0.0867 - val_f2_m: 0.1676 - val_f3_m: 0.2460 - val_f4_m: 0.3072\n",
            "Epoch 7/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.6088 - acc: 0.2283 - recall_m: 0.6566 - precision_m: 0.0582 - f1_m: 0.1049 - f2_m: 0.2050 - f3_m: 0.3052 - f4_m: 0.3861 - val_loss: 0.6895 - val_acc: 0.5623 - val_recall_m: 0.4981 - val_precision_m: 0.0666 - val_f1_m: 0.1156 - val_f2_m: 0.2097 - val_f3_m: 0.2912 - val_f4_m: 0.3489\n",
            "Epoch 8/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.5545 - acc: 0.6047 - recall_m: 0.7358 - precision_m: 0.1109 - f1_m: 0.1872 - f2_m: 0.3273 - f3_m: 0.4449 - f4_m: 0.5270 - val_loss: 0.6702 - val_acc: 0.6547 - val_recall_m: 0.4981 - val_precision_m: 0.0846 - val_f1_m: 0.1417 - val_f2_m: 0.2420 - val_f3_m: 0.3214 - val_f4_m: 0.3741\n",
            "Epoch 9/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.5737 - acc: 0.6689 - recall_m: 0.6500 - precision_m: 0.1376 - f1_m: 0.2144 - f2_m: 0.3396 - f3_m: 0.4354 - f4_m: 0.4988 - val_loss: 0.6713 - val_acc: 0.4849 - val_recall_m: 0.4981 - val_precision_m: 0.0612 - val_f1_m: 0.1070 - val_f2_m: 0.1972 - val_f3_m: 0.2782 - val_f4_m: 0.3373\n",
            "Epoch 10/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.5010 - acc: 0.7882 - recall_m: 0.6858 - precision_m: 0.1805 - f1_m: 0.2743 - f2_m: 0.4158 - f3_m: 0.5120 - f4_m: 0.5693 - val_loss: 0.6201 - val_acc: 0.8660 - val_recall_m: 0.4981 - val_precision_m: 0.1883 - val_f1_m: 0.2591 - val_f2_m: 0.3497 - val_f3_m: 0.4051 - val_f4_m: 0.4366\n",
            "Epoch 11/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.5152 - acc: 0.7646 - recall_m: 0.6509 - precision_m: 0.1771 - f1_m: 0.2647 - f2_m: 0.3948 - f3_m: 0.4836 - f4_m: 0.5375 - val_loss: 0.6257 - val_acc: 0.7528 - val_recall_m: 0.4981 - val_precision_m: 0.1154 - val_f1_m: 0.1810 - val_f2_m: 0.2832 - val_f3_m: 0.3555 - val_f4_m: 0.4003\n",
            "Epoch 12/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.4294 - acc: 0.8684 - recall_m: 0.6906 - precision_m: 0.2875 - f1_m: 0.3814 - f2_m: 0.5030 - f3_m: 0.5754 - f4_m: 0.6154 - val_loss: 0.5991 - val_acc: 0.9358 - val_recall_m: 0.4528 - val_precision_m: 0.2491 - val_f1_m: 0.3086 - val_f2_m: 0.3735 - val_f3_m: 0.4070 - val_f4_m: 0.4239\n",
            "Epoch 13/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.4485 - acc: 0.9104 - recall_m: 0.6179 - precision_m: 0.3691 - f1_m: 0.4385 - f2_m: 0.5188 - f3_m: 0.5606 - f4_m: 0.5818 - val_loss: 0.5765 - val_acc: 0.8208 - val_recall_m: 0.4981 - val_precision_m: 0.1604 - val_f1_m: 0.2345 - val_f2_m: 0.3345 - val_f3_m: 0.3963 - val_f4_m: 0.4312\n",
            "Epoch 14/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.4564 - acc: 0.8712 - recall_m: 0.6247 - precision_m: 0.2706 - f1_m: 0.3508 - f2_m: 0.4593 - f3_m: 0.5241 - f4_m: 0.5596 - val_loss: 0.5857 - val_acc: 0.8887 - val_recall_m: 0.4830 - val_precision_m: 0.1920 - val_f1_m: 0.2558 - val_f2_m: 0.3417 - val_f3_m: 0.3949 - val_f4_m: 0.4251\n",
            "Epoch 15/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.4212 - acc: 0.9146 - recall_m: 0.6472 - precision_m: 0.3921 - f1_m: 0.4596 - f2_m: 0.5428 - f3_m: 0.5868 - f4_m: 0.6091 - val_loss: 0.5446 - val_acc: 0.9604 - val_recall_m: 0.4981 - val_precision_m: 0.3011 - val_f1_m: 0.3636 - val_f2_m: 0.4281 - val_f3_m: 0.4590 - val_f4_m: 0.4739\n",
            "Epoch 16/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.4383 - acc: 0.9292 - recall_m: 0.6053 - precision_m: 0.3885 - f1_m: 0.4493 - f2_m: 0.5200 - f3_m: 0.5563 - f4_m: 0.5745 - val_loss: 0.5468 - val_acc: 0.9679 - val_recall_m: 0.4981 - val_precision_m: 0.3170 - val_f1_m: 0.3689 - val_f2_m: 0.4263 - val_f3_m: 0.4564 - val_f4_m: 0.4717\n",
            "Epoch 17/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.3643 - acc: 0.9311 - recall_m: 0.6808 - precision_m: 0.4402 - f1_m: 0.5078 - f2_m: 0.5876 - f3_m: 0.6278 - f4_m: 0.6477 - val_loss: 0.5685 - val_acc: 0.9755 - val_recall_m: 0.4377 - val_precision_m: 0.3245 - val_f1_m: 0.3608 - val_f2_m: 0.3980 - val_f3_m: 0.4157 - val_f4_m: 0.4241\n",
            "Epoch 18/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.3115 - acc: 0.9434 - recall_m: 0.7377 - precision_m: 0.4830 - f1_m: 0.5624 - f2_m: 0.6452 - f3_m: 0.6855 - f4_m: 0.7052 - val_loss: 0.5254 - val_acc: 0.9849 - val_recall_m: 0.4981 - val_precision_m: 0.3811 - val_f1_m: 0.4207 - val_f2_m: 0.4590 - val_f3_m: 0.4766 - val_f4_m: 0.4849\n",
            "Epoch 19/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.4036 - acc: 0.9476 - recall_m: 0.6226 - precision_m: 0.5070 - f1_m: 0.5365 - f2_m: 0.5757 - f3_m: 0.5959 - f4_m: 0.6059 - val_loss: 0.5767 - val_acc: 0.9434 - val_recall_m: 0.4528 - val_precision_m: 0.2111 - val_f1_m: 0.2758 - val_f2_m: 0.3504 - val_f3_m: 0.3916 - val_f4_m: 0.4135\n",
            "Epoch 20/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.4065 - acc: 0.9392 - recall_m: 0.6274 - precision_m: 0.4645 - f1_m: 0.5107 - f2_m: 0.5634 - f3_m: 0.5905 - f4_m: 0.6041 - val_loss: 0.5309 - val_acc: 0.9792 - val_recall_m: 0.4981 - val_precision_m: 0.3736 - val_f1_m: 0.4132 - val_f2_m: 0.4536 - val_f3_m: 0.4731 - val_f4_m: 0.4826\n",
            "Epoch 21/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.3834 - acc: 0.9292 - recall_m: 0.6585 - precision_m: 0.4317 - f1_m: 0.5001 - f2_m: 0.5734 - f3_m: 0.6100 - f4_m: 0.6281 - val_loss: 0.5336 - val_acc: 0.9774 - val_recall_m: 0.4830 - val_precision_m: 0.3698 - val_f1_m: 0.4045 - val_f2_m: 0.4414 - val_f3_m: 0.4595 - val_f4_m: 0.4684\n",
            "Epoch 22/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.3411 - acc: 0.9401 - recall_m: 0.7009 - precision_m: 0.4468 - f1_m: 0.5207 - f2_m: 0.6033 - f3_m: 0.6451 - f4_m: 0.6660 - val_loss: 0.5349 - val_acc: 0.9830 - val_recall_m: 0.4830 - val_precision_m: 0.3849 - val_f1_m: 0.4136 - val_f2_m: 0.4455 - val_f3_m: 0.4617 - val_f4_m: 0.4697\n",
            "Epoch 23/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.3361 - acc: 0.9575 - recall_m: 0.6877 - precision_m: 0.5506 - f1_m: 0.5957 - f2_m: 0.6407 - f3_m: 0.6616 - f4_m: 0.6716 - val_loss: 0.5313 - val_acc: 0.9811 - val_recall_m: 0.4830 - val_precision_m: 0.3774 - val_f1_m: 0.4060 - val_f2_m: 0.4401 - val_f3_m: 0.4582 - val_f4_m: 0.4674\n",
            "Epoch 24/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.3727 - acc: 0.9542 - recall_m: 0.6519 - precision_m: 0.5151 - f1_m: 0.5563 - f2_m: 0.6013 - f3_m: 0.6234 - f4_m: 0.6341 - val_loss: 0.5287 - val_acc: 0.9830 - val_recall_m: 0.4830 - val_precision_m: 0.3849 - val_f1_m: 0.4136 - val_f2_m: 0.4455 - val_f3_m: 0.4617 - val_f4_m: 0.4697\n",
            "Epoch 25/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.4175 - acc: 0.9462 - recall_m: 0.6075 - precision_m: 0.4549 - f1_m: 0.5058 - f2_m: 0.5559 - f3_m: 0.5791 - f4_m: 0.5900 - val_loss: 0.5325 - val_acc: 0.9774 - val_recall_m: 0.4830 - val_precision_m: 0.3472 - val_f1_m: 0.3879 - val_f2_m: 0.4319 - val_f3_m: 0.4539 - val_f4_m: 0.4648\n",
            "Epoch 26/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.3444 - acc: 0.9594 - recall_m: 0.6792 - precision_m: 0.5274 - f1_m: 0.5774 - f2_m: 0.6273 - f3_m: 0.6504 - f4_m: 0.6615 - val_loss: 0.5290 - val_acc: 0.9830 - val_recall_m: 0.4830 - val_precision_m: 0.3849 - val_f1_m: 0.4136 - val_f2_m: 0.4455 - val_f3_m: 0.4617 - val_f4_m: 0.4697\n",
            "Epoch 27/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.3889 - acc: 0.9561 - recall_m: 0.6387 - precision_m: 0.4934 - f1_m: 0.5362 - f2_m: 0.5842 - f3_m: 0.6080 - f4_m: 0.6196 - val_loss: 0.5278 - val_acc: 0.9830 - val_recall_m: 0.4830 - val_precision_m: 0.3849 - val_f1_m: 0.4136 - val_f2_m: 0.4455 - val_f3_m: 0.4617 - val_f4_m: 0.4697\n",
            "Epoch 28/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.3742 - acc: 0.9566 - recall_m: 0.6491 - precision_m: 0.5151 - f1_m: 0.5569 - f2_m: 0.6006 - f3_m: 0.6218 - f4_m: 0.6321 - val_loss: 0.5287 - val_acc: 0.9830 - val_recall_m: 0.4830 - val_precision_m: 0.3849 - val_f1_m: 0.4136 - val_f2_m: 0.4455 - val_f3_m: 0.4617 - val_f4_m: 0.4697\n",
            "Epoch 00028: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBdWXjIZyaat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(f\"/content/gdrive/My Drive/CNN_LSTM_{I}_final.hdf5\")\n",
        "preds = model.predict([x_val_0, x_val_1, x_val_2, num_val_0, num_val_1, num_val_2, adj_val_0, adj_val_1, adj_val_2])\n",
        "#np.save(f'/content/gdrive/My Drive/preds_{I}', preds)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDev-TxY0hxU",
        "colab_type": "code",
        "outputId": "df97447a-4734-4602-a5cc-9ba9d1515c40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, fbeta_score, cohen_kappa_score\n",
        "\n",
        "print(accuracy_score(y_val, preds.round().flatten()))\n",
        "print(f1_score(y_val, preds.round().flatten()))\n",
        "print(fbeta_score(y_val, preds.round().flatten(),2))\n",
        "print(fbeta_score(y_val, preds.round().flatten(),3))\n",
        "print(fbeta_score(y_val, preds.round().flatten(),4))\n",
        "print(cohen_kappa_score(y_val, preds.round().flatten()))\n",
        "print(recall_score(y_val, preds.round().flatten()))\n",
        "print(precision_score(y_val, preds.round().flatten()))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9849056603773585\n",
            "0.8260869565217391\n",
            "0.9223300970873787\n",
            "0.9595959595959596\n",
            "0.9758308157099699\n",
            "0.8184465187976364\n",
            "1.0\n",
            "0.7037037037037037\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga2a6_MmHKd2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_imgs_0 = np.load('/content/gdrive/My Drive/test_data.npz')['test_imgs_0']\n",
        "test_imgs_1 = np.load('/content/gdrive/My Drive/test_data.npz')['test_imgs_1']\n",
        "test_imgs_2 = np.load('/content/gdrive/My Drive/test_data.npz')['test_imgs_2']\n",
        "test_adj_0 = np.load('/content/gdrive/My Drive/test_data.npz')['test_adj_0']\n",
        "test_adj_1 = np.load('/content/gdrive/My Drive/test_data.npz')['test_adj_1']\n",
        "test_adj_2 = np.load('/content/gdrive/My Drive/test_data.npz')['test_adj_2']\n",
        "test_labs = np.load('/content/gdrive/My Drive/test_data.npz')['test_lab']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTwOtAYZIDsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_gsod = pd.read_csv('/content/gdrive/My Drive/test_gsod_final.csv').values\n",
        "test_gsod_0, test_gsod_1, test_gsod_2 = test_gsod[:-2,:], test_gsod[1:-1,:], test_gsod[2:,:10]\n",
        "for i in range(1,25):\n",
        "    test_gsod_0 = np.concatenate([test_gsod_0, test_gsod[:-2,:]])\n",
        "    test_gsod_1 = np.concatenate([test_gsod_1, test_gsod[1:-1,:]])\n",
        "    test_gsod_2 = np.concatenate([test_gsod_2, test_gsod[2:,:10]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksczuhKsID-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "I = 2\n",
        "model.load_weights(f\"/content/gdrive/My Drive/CNN_LSTM_{I}_final.hdf5\")\n",
        "test_preds = model.predict([test_imgs_0, test_imgs_1, test_imgs_2, test_gsod_0, test_gsod_1, test_gsod_2, test_adj_0, test_adj_1, test_adj_2])\n",
        "np.save(f'/content/gdrive/My Drive/test_preds_{I}', test_preds.flatten())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXwa9EY3IF1Z",
        "colab_type": "code",
        "outputId": "7f118c0f-eed1-4149-c47d-a982069b3fa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, fbeta_score, cohen_kappa_score\n",
        "\n",
        "print(accuracy_score(test_labs, test_preds.round().flatten()))\n",
        "print(f1_score(test_labs, test_preds.round().flatten()))\n",
        "print(fbeta_score(test_labs, test_preds.round().flatten(),2))\n",
        "print(fbeta_score(test_labs, test_preds.round().flatten(),3))\n",
        "print(fbeta_score(test_labs, test_preds.round().flatten(),4))\n",
        "print(cohen_kappa_score(test_labs, test_preds.round().flatten()))\n",
        "print(recall_score(test_labs, test_preds.round().flatten()))\n",
        "print(precision_score(test_labs, test_preds.round().flatten()))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8533333333333334\n",
            "0.8405797101449276\n",
            "0.847953216374269\n",
            "0.8504398826979472\n",
            "0.85146804835924\n",
            "0.7048300536672629\n",
            "0.8529411764705882\n",
            "0.8285714285714286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icAtszTSIHCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}