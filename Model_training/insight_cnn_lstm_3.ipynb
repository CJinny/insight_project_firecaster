{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "insight_cnn_lstm_3.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvhZfItlx6Ve",
        "colab_type": "code",
        "outputId": "e6c826fe-4acd-451b-f29a-66bae6ec45e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pylab as plt\n",
        "from PIL import Image\n",
        "import matplotlib\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import keras\n",
        "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, TensorBoard\n",
        "from keras import optimizers\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dropout, UpSampling2D, BatchNormalization, Activation, Dense, Lambda, TimeDistributed, Flatten\n",
        "from keras.layers import LSTM, GRU, RNN, Reshape, CuDNNGRU, CuDNNLSTM\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D, MaxPooling3D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv3D\n",
        "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
        "from keras import backend as K\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import Callback\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import tensorflow as tf\n",
        "import gc\n",
        "from keras import layers, models, applications\n",
        "from keras.layers import concatenate\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras import layers, models, applications\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "from keras.backend.tensorflow_backend import set_session\n",
        "from keras.backend.tensorflow_backend import clear_session\n",
        "from keras.backend.tensorflow_backend import get_session\n",
        "import tensorflow\n",
        "# Reset Keras Session\n",
        "def reset_keras():\n",
        "    sess = get_session()\n",
        "    clear_session()\n",
        "    sess.close()\n",
        "    sess = get_session()\n",
        "    try:\n",
        "        del classifier # this is from global space - change this as you need\n",
        "    except:\n",
        "        pass\n",
        "    print(gc.collect()) # if it's done something you should see a number being outputted\n",
        "\n",
        "    # use the same config as you used to create the session\n",
        "    config = tensorflow.ConfigProto()\n",
        "    config.gpu_options.per_process_gpu_memory_fraction = 1\n",
        "    config.gpu_options.visible_device_list = \"0\"\n",
        "    set_session(tensorflow.Session(config=config))\n",
        "\n",
        "def random_everything(seed=42):\n",
        "  os.environ['PYTHONHASHSEED'] = str(42)\n",
        "  random.seed(42)\n",
        "  np.random.seed(42)\n",
        "  tf.set_random_seed(42)\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "def f2_m(y_true, y_pred, beta=2):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return (1+beta**2) * (precision*recall) / ((beta**2)*(precision)+recall+K.epsilon())\n",
        "\n",
        "def f3_m(y_true, y_pred, beta=3):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return (1+beta**2) * (precision*recall) / ((beta**2)*(precision)+recall+K.epsilon())\n",
        "\n",
        "def f4_m(y_true, y_pred, beta=4):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return (1+beta**2) * (precision*recall) / ((beta**2)*(precision)+recall+K.epsilon())\n",
        "    \n",
        "'''\n",
        "a = []\n",
        "while(1):\n",
        "  a.append('1')\n",
        "'''\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\na = []\\nwhile(1):\\n  a.append('1')\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK5PHHTwx_MI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ConvBlock(inputs, suffix=0, prefix=\"cnn\"):\n",
        "    \"\"\"no final linear dense layer!\"\"\"\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name=f\"{prefix}_{suffix}_conv_1a\")(inputs)\n",
        "    conv1 = BatchNormalization(name=f\"{prefix}_{suffix}_batchnorm_1a\")(conv1)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name=f\"{prefix}_{suffix}_conv_1b\")(conv1)\n",
        "    conv1 = BatchNormalization(name=f\"{prefix}_{suffix}_batchnorm_1b\")(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2), name=f\"{prefix}_{suffix}_maxpool_1\")(conv1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name=f\"{prefix}_{suffix}_conv_2a\")(pool1)\n",
        "    conv2 = BatchNormalization(name=f\"{prefix}_{suffix}_batchnorm_2a\")(conv2)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name=f\"{prefix}_{suffix}_conv_2b\")(conv2)\n",
        "    conv2 = BatchNormalization(name=f\"{prefix}_{suffix}_batchnorm_2b\")(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2), name=f\"index_{suffix}_maxpool_2\")(conv2)\n",
        "    \n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name=f\"{prefix}_{suffix}_conv_3a\")(pool2)\n",
        "    conv3 = BatchNormalization(name=f\"{prefix}_{suffix}_batchnorm_3a\")(conv3)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name=f\"{prefix}_{suffix}_conv_3b\")(conv3)\n",
        "    conv3 = BatchNormalization(name=f\"{prefix}_{suffix}_batchnorm_3b\")(conv3)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name=f\"{prefix}_{suffix}_conv_3c\")(conv3)\n",
        "    conv3 = BatchNormalization(name=f\"{prefix}_{suffix}_batchnorm_3c\")(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2), name=f\"index_{suffix}_maxpool_3\")(conv3)\n",
        "\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name=f\"{prefix}_{suffix}_conv_4a\")(pool3)\n",
        "    conv4 = BatchNormalization(name=f\"{prefix}_{suffix}_batchnorm_4a\")(conv4)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name=f\"{prefix}_{suffix}_conv_4b\")(conv4)\n",
        "    conv4 = BatchNormalization(name=f\"{prefix}_{suffix}_batchnorm_4b\")(conv4)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name=f\"{prefix}_{suffix}_conv_4c\")(conv4)\n",
        "    conv4 = BatchNormalization(name=f\"{prefix}_{suffix}_batchnorm_4c\")(conv4)    \n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2), name=f\"{prefix}_{suffix}_maxpool_4\")(conv4)    \n",
        "\n",
        "    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name=f\"{prefix}_{suffix}_conv_5a\")(pool4)\n",
        "    conv5 = BatchNormalization(name=f\"{prefix}_{suffix}_batchnorm_5a\")(conv5)\n",
        "    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name=f\"{prefix}_{suffix}_conv_5b\")(conv5)\n",
        "    conv5 = BatchNormalization(name=f\"{prefix}_{suffix}_batchnorm_5b\")(conv5)\n",
        "    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name=f\"{prefix}_{suffix}_conv_5c\")(conv5)\n",
        "    conv5 = BatchNormalization(name=f\"{prefix}_{suffix}_batchnorm_5c\")(conv5)    \n",
        "    pool5 = MaxPooling2D(pool_size=(2, 2), name=f\"{prefix}_{suffix}_maxpool_5\")(conv5)   \n",
        "    \n",
        "    flatten= Flatten(name=f\"{prefix}_{suffix}_flatten\")(pool5)\n",
        "    dense1 = Dense(512, activation=\"relu\", name=f\"{prefix}_{suffix}_relu_1\")(flatten)\n",
        "    drop1  = Dropout(0.4, name=f\"{prefix}_{suffix}_drop_1\")(dense1)\n",
        "    dense2 = Dense(128, activation=\"relu\", name=f\"{prefix}_{suffix}_relu_2\")(drop1)\n",
        "    drop2  = Dropout(0.3, name=f\"{prefix}_{suffix}_drop_2\")(dense2)\n",
        "    dense3 = Dense(32, activation=\"relu\", name=f\"{prefix}_{suffix}_relu_3\")(drop2)\n",
        "    drop3  = Dropout(0.2, name=f\"{prefix}_{suffix}_drop_3\")(dense3)\n",
        "    dense4 = Dense(8, activation=\"relu\",  name=f\"{prefix}_{suffix}_relu_4\")(drop3)\n",
        "    return dense4\n",
        "\n",
        "def MLP(inputs, suffix=0, prefix='mlp'):\n",
        "    dense = Dense(8, activation='relu', name=f\"{prefix}_{suffix}_relu_1\")(inputs)\n",
        "    dense = Dense(4, activation='relu', name=f\"{prefix}_{suffix}_relu_2\")(dense)\n",
        "    return dense\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCztHbTjx_O4",
        "colab_type": "code",
        "outputId": "dc191705-20e4-451b-8ccd-818911623349",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "n_channels = 14\n",
        "sector_dim = 200\n",
        "\n",
        "img_0 = Input((sector_dim,sector_dim,n_channels), name=\"cnn_input_0\")\n",
        "img_1 = Input((sector_dim,sector_dim,n_channels), name=\"cnn_input_1\")\n",
        "img_2 = Input((sector_dim,sector_dim,n_channels), name=\"cnn_input_2\")\n",
        "\n",
        "num_0 = Input((50,), name=\"gsod_input_0\")\n",
        "num_1 = Input((50,), name=\"gsod_input_1\")\n",
        "num_2 = Input((10,), name=\"gsod_input_2\")\n",
        "\n",
        "adj_0 = Input((8,), name=\"adj_input_0\")\n",
        "adj_1 = Input((8,), name=\"adj_input_1\")\n",
        "adj_2 = Input((8,), name=\"adj_input_2\")\n",
        "\n",
        "cnn_0 = ConvBlock(img_0, suffix=0)\n",
        "cnn_1 = ConvBlock(img_1, suffix=1)\n",
        "cnn_2 = ConvBlock(img_2, suffix=2)\n",
        "\n",
        "num_0_m = MLP(num_0, suffix=0, prefix=\"gsod\")\n",
        "num_1_m = MLP(num_1, suffix=1, prefix=\"gsod\")\n",
        "num_2_m = MLP(num_2, suffix=2, prefix=\"gsod\")\n",
        "\n",
        "adj_0_m = MLP(adj_0, suffix=0, prefix=\"adj\")\n",
        "adj_1_m = MLP(adj_1, suffix=1, prefix=\"adj\")\n",
        "adj_2_m = MLP(adj_2, suffix=2, prefix=\"adj\")\n",
        "\n",
        "mixed_0 = concatenate([cnn_0, num_0_m, adj_0_m], name='mixed_0')\n",
        "mixed_1 = concatenate([cnn_1, num_1_m, adj_1_m], name='mixed_1')\n",
        "mixed_2 = concatenate([cnn_2, num_2_m, adj_2_m], name='mixed_2')\n",
        "\n",
        "concat   = concatenate([mixed_0, mixed_1, mixed_2], name=\"concat_mixed\")\n",
        "reshape  = Reshape((3, -1), name=\"reshape\")(concat)\n",
        "lstm     = LSTM(256, name='lstm_1', return_sequences=True)(reshape)\n",
        "lstm     = Dropout(0.4, name='lstm_drop_1')(lstm)\n",
        "lstm     = LSTM(256, name='lstm_2')(lstm)\n",
        "lstm     = Dropout(0.4, name='lstm_drop_2')(lstm)\n",
        "dense    = Dense(10, activation=\"relu\", name=\"fc_relu\")(lstm)\n",
        "dense    = Dense(1, activation=\"sigmoid\", name=\"fc_sigmoid\")(dense)\n",
        "\n",
        "model = Model(inputs=[img_0, img_1, img_2, num_0, num_1, num_2, adj_0, adj_1, adj_2], output=dense)\n",
        "#model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"fc...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTHr9G2yx_Rc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Data(object):\n",
        "    def __init__(self, imgs, labs, zone_idx=np.arange(20), size=108):\n",
        "        self.imgs = imgs\n",
        "        self.labs = labs\n",
        "        self.size = size\n",
        "        self.zone_idx = zone_idx\n",
        "\n",
        "    def extract_single_zone(self, imgs, labs, idx=0):\n",
        "        \"\"\"extract a single zone based on the index\"\"\"\n",
        "        assert idx >= 0 and idx <= 24\n",
        "        try:\n",
        "            assert len(imgs) == self.size\n",
        "        except Exception:\n",
        "            imgs = imgs[:self.size,:]     ## if there are more images than labels, cut the images to approporiate size!\n",
        "        try:\n",
        "            assert len(labs) == self.size\n",
        "        except Exception:\n",
        "            labs = labs[:self.size,:]     \n",
        "\n",
        "        row_idx = idx//5\n",
        "        col_idx = idx%5\n",
        "        return imgs[:, row_idx*200:(row_idx+1)*200, col_idx*200:(col_idx+1)*200, :], labs[:, row_idx*200:(row_idx+1)*200, col_idx*200:(col_idx+1)*200, :]\n",
        "   \n",
        "    def burn_ratio(self, labs):\n",
        "        \"\"\"calculate the burn ratio in an area\"\"\"\n",
        "        ratio = np.zeros((labs.shape[0],))\n",
        "        for i in range(len(labs)):\n",
        "          ratio[i] = labs[i,:,:,:].mean()\n",
        "        return ratio\n",
        "\n",
        "    def binarize_risk(self, labs, thres=0.05):\n",
        "        #ratio = labs.sum(axis=-1).sum(axis=-1).sum(axis=-1)/(200*200)\n",
        "        ratio = self.burn_ratio(labs)\n",
        "        return (ratio>thres).astype(int)\n",
        "\n",
        "    def compile_zones(self):\n",
        "        \"\"\"concatenate all sector images based on selected index\"\"\"\n",
        "        \"\"\"Zone 0,0,0,0,0,0,0,0,0 .... Zone 1,1,1,1....\"\"\"\n",
        "        \"\"\"Normalize to (0, 1) !!!\"\"\"\n",
        "        imgs, labs = self.extract_single_zone(self.imgs, self.labs, idx=self.zone_idx[0])\n",
        "        for i in range(1, len(self.zone_idx)):\n",
        "            I, L = self.extract_single_zone(self.imgs, self.labs, idx=self.zone_idx[i])\n",
        "            imgs = np.concatenate([imgs, I], 0)\n",
        "            labs = np.concatenate([labs, L], 0)\n",
        "        imgs = imgs/imgs.max()\n",
        "        imgs = imgs.astype('float32')\n",
        "        return imgs, labs\n",
        "        \n",
        "    def prepare_step_data(self):\n",
        "        zoned_imgs, zoned_labs = self.compile_zones()\n",
        "        idx = np.array([i for i in range(len(zoned_imgs)) if i % self.size not in [self.size-2, self.size-1, self.size]])\n",
        "        imgs_0 = zoned_imgs[idx, :,:,:]\n",
        "        imgs_1 = zoned_imgs[idx+1, :,:,:]\n",
        "        imgs_2, labs = zoned_imgs[idx+2, :,:,:], self.binarize_risk(zoned_labs[idx+2])\n",
        "        return imgs_0, imgs_1, imgs_2, labs\n",
        "\n",
        "\n",
        "class Adjacency(object):\n",
        "    \"\"\"Only to extract burn ratio from label, no images, no binarized labels, burn ratio is the feature to extract\"\"\"\n",
        "    def __init__(self, labs, zone_idx=np.arange(20), size=108):\n",
        "        self.labs = labs\n",
        "        self.size = size\n",
        "        self.zone_idx = zone_idx\n",
        "    \n",
        "    def extract_single_zone(self, labs, idx=0):\n",
        "        \"\"\"extract a single zone based on the index\"\"\"\n",
        "        assert idx >= 0 and idx <= 24\n",
        "        try:\n",
        "            assert len(labs) == self.size\n",
        "        except Exception:\n",
        "            labs = labs[:self.size,:]     \n",
        "        row_idx = idx//5\n",
        "        col_idx = idx%5\n",
        "        return labs[:, row_idx*200:(row_idx+1)*200, col_idx*200:(col_idx+1)*200, :]\n",
        "\n",
        "    def burn_ratio(self,labs):\n",
        "        \"\"\"calculate the burn ratio in an area\"\"\"\n",
        "        ratio = np.zeros((labs.shape[0],))\n",
        "        for i in range(len(labs)):\n",
        "          ratio[i] = labs[i,:,:,:].mean()\n",
        "        return ratio\n",
        "    \n",
        "    def binarize_risk(self,labs, thres=0.05):\n",
        "        ratio = labs.sum(axis=-1).sum(axis=-1).sum(axis=-1)/(200*200)\n",
        "        return (ratio>thres).astype(int)\n",
        "\n",
        "    def compile_zones(self):\n",
        "        \"\"\"concatenate all sector images based on selected index\"\"\"\n",
        "        \"\"\"Zone 0,0,0,0,0,0,0,0,0 .... Zone 1,1,1,1....\"\"\"\n",
        "        \"\"\"Normalize to (0, 1) !!!\"\"\"\n",
        "        labs = self.extract_single_zone(self.labs, idx=self.zone_idx[0])\n",
        "        for i in range(1, len(self.zone_idx)):\n",
        "            L = self.extract_single_zone(self.labs, idx=self.zone_idx[i])\n",
        "            labs = np.concatenate([labs, L], 0)\n",
        "        return labs\n",
        "\n",
        "    def prepare_step_data(self):\n",
        "        zoned_labs = self.compile_zones()\n",
        "        idx = np.array([i for i in range(len(zoned_labs)) if i % self.size not in [self.size-2, self.size-1, self.size]])\n",
        "        adj_0 = self.burn_ratio(zoned_labs[idx])\n",
        "        adj_1 = self.burn_ratio(zoned_labs[idx+1])\n",
        "        adj_2 = self.burn_ratio(zoned_labs[idx+2])\n",
        "        return adj_0, adj_1, adj_2\n",
        "\n",
        "def extract_adjacency_feature(indices, mode='trn_val'):\n",
        "    \"\"\"\n",
        "    Function to extract adjacency features\n",
        "    indices must be in list format,\n",
        "    mode can be either trn_val or test\n",
        "    \"\"\"\n",
        "    names = ['south','southwest','west','northwest','north','northeast','east','southeast']\n",
        "    \n",
        "    def subset_adjacency(which=0):\n",
        "        \"\"\"Extract adjacency feature based on 1 direction\"\"\"\n",
        "        name = names[which]\n",
        "        row = 200\n",
        "        col = 200\n",
        "        if 'south' in name:\n",
        "            row = 400\n",
        "        elif 'north' in name:\n",
        "            row = 0\n",
        "        if 'west' in name:\n",
        "            col = 0\n",
        "        elif 'east' in name:\n",
        "            col = 400\n",
        "        return adjacency_full[:,row:row+1000,col:col+1000,:]\n",
        "    \n",
        "    if mode == 'trn_val':\n",
        "        trn_adj_0_list = []\n",
        "        trn_adj_1_list = []\n",
        "        trn_adj_2_list = []\n",
        "    \n",
        "        val_adj_0_list = []\n",
        "        val_adj_1_list = []\n",
        "        val_adj_2_list = []\n",
        "\n",
        "        trn_idx = indices[0]\n",
        "        val_idx = indices[1]\n",
        "        for i in tqdm_notebook(range(8)):\n",
        "            adjacency_full = np.load('/content/gdrive/My Drive/adjacency.npz')['dnbr']\n",
        "            adjacency = subset_adjacency(which=i)\n",
        "            \"\"\"binarize to burn or unburnt pixels\"\"\"\n",
        "            adjacency = (adjacency>0.66).astype(int)\n",
        "            \"\"\"Adjacency feature is always taken on timestep prior!!! This is to avoid data leakage!!!\"\"\"\n",
        "            adjacency = np.concatenate([np.zeros((1,1000,1000,1), dtype='int'), adjacency[:-1]],0)\n",
        "            del adjacency_full\n",
        "            gc.collect()\n",
        "            trn_data = Adjacency(adjacency, zone_idx=trn_idx)\n",
        "            val_data = Adjacency(adjacency, zone_idx=val_idx)\n",
        "            del adjacency\n",
        "            gc.collect()\n",
        "            trn_adj_0, trn_adj_1, trn_adj_2 = trn_data.prepare_step_data()\n",
        "            val_adj_0, val_adj_1, val_adj_2 = val_data.prepare_step_data()\n",
        "            del trn_data, val_data\n",
        "            gc.collect()\n",
        "            trn_adj_0_list.append(trn_adj_0)\n",
        "            trn_adj_1_list.append(trn_adj_1)\n",
        "            trn_adj_2_list.append(trn_adj_2)\n",
        "            val_adj_0_list.append(val_adj_0)\n",
        "            val_adj_1_list.append(val_adj_1)\n",
        "            val_adj_2_list.append(val_adj_2)\n",
        "\n",
        "        trn_adj_0_list = np.column_stack(trn_adj_0_list)\n",
        "        trn_adj_1_list = np.column_stack(trn_adj_1_list)\n",
        "        trn_adj_2_list = np.column_stack(trn_adj_2_list)\n",
        "        val_adj_0_list = np.column_stack(val_adj_0_list)\n",
        "        val_adj_1_list = np.column_stack(val_adj_1_list)\n",
        "        val_adj_2_list = np.column_stack(val_adj_2_list)\n",
        "\n",
        "        return trn_adj_0_list, trn_adj_1_list, trn_adj_2_list, val_adj_0_list, val_adj_1_list, val_adj_2_list\n",
        "\n",
        "    elif mode == 'test':\n",
        "        test_adj_0_list = []\n",
        "        test_adj_1_list = []\n",
        "        test_adj_2_list = []\n",
        "\n",
        "        test_idx = indices[0]\n",
        "        for i in tqdm_notebook(range(8)):\n",
        "            adjacency_full = np.load('/content/gdrive/My Drive/adjacency.npz')['dnbr']\n",
        "            adjacency = subset_adjacency(which=i)\n",
        "            adjacency = (adjacency>0.66).astype(int)\n",
        "            adjacency = np.concatenate([np.zeros((1,1000,1000,1), dtype='int'), adjacency[:-1]],0)\n",
        "            del adjacency_full\n",
        "            gc.collect()\n",
        "            test_data = Adjacency(adjacency, zone_idx=test_idx)\n",
        "            del adjacency\n",
        "            gc.collect()\n",
        "            test_adj_0, test_adj_1, test_adj_2 = test_data.prepare_step_data()\n",
        "            del test_data\n",
        "            gc.collect()\n",
        "            test_adj_0_list.append(test_adj_0)\n",
        "            test_adj_1_list.append(test_adj_1)\n",
        "            test_adj_2_list.append(test_adj_2)\n",
        "\n",
        "        test_adj_0_list = np.column_stack(test_adj_0_list)\n",
        "        test_adj_1_list = np.column_stack(test_adj_1_list)\n",
        "        test_adj_2_list = np.column_stack(test_adj_2_list)\n",
        "\n",
        "        return test_adj_0_list, test_adj_1_list, test_adj_2_list\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NNA-XVTy8cj",
        "colab_type": "code",
        "outputId": "6f81ac78-ceb1-4113-c6b3-e34301e20669",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "from google.colab import drive\n",
        "#drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "\n",
        "water_mask = np.load('/content/gdrive/My Drive/water_mask_based_on_ndvi_565.npy')\n",
        "water_mask = np.expand_dims(water_mask, 2)\n",
        "plt.imshow(water_mask[:,:,0], cmap='Greys_r')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fea01207780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npOaMgNScEZCaMwJSc0ZAas4ISM39H6skPSAMIXjsAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVK7w7oVy8f2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "I = 3\n",
        "trn_idx = [i for i in range(25) if i not in range(5*I, 5*I+5)]\n",
        "val_idx = [i for i in range(25) if i in range(5*I, 5*I+5)]\n",
        "\n",
        "imgs = np.load('/content/gdrive/My Drive/cloud_control_data.npz')['imgs']\n",
        "dnbr = np.load('/content/gdrive/My Drive/adjacency.npz')['dnbr']\n",
        "dnbr = dnbr[:,200:1200,200:1200,:]\n",
        "\n",
        "labs = (dnbr>0.66).astype(int)\n",
        "del dnbr\n",
        "gc.collect()\n",
        "## apply water mask\n",
        "for i in range(len(labs)):\n",
        "    labs[i,:][water_mask==1] = 0\n",
        "\n",
        "trn_data = Data(imgs, labs, zone_idx=trn_idx)\n",
        "val_data = Data(imgs, labs, zone_idx=val_idx)\n",
        "\n",
        "del imgs, labs\n",
        "gc.collect()\n",
        "\n",
        "x_trn_0, x_trn_1, x_trn_2, y_trn = trn_data.prepare_step_data()\n",
        "x_val_0, x_val_1, x_val_2, y_val = val_data.prepare_step_data()\n",
        "\n",
        "del trn_data, val_data, water_mask\n",
        "gc.collect()\n",
        "\n",
        "try:\n",
        "    adj_trn_0 = np.load(f'/content/gdrive/My Drive/adjacency_features_{I}.npz')['adj_trn_0']\n",
        "    adj_trn_1 = np.load(f'/content/gdrive/My Drive/adjacency_features_{I}.npz')['adj_trn_1']\n",
        "    adj_trn_2 = np.load(f'/content/gdrive/My Drive/adjacency_features_{I}.npz')['adj_trn_2']\n",
        "\n",
        "    adj_val_0 = np.load(f'/content/gdrive/My Drive/adjacency_features_{I}.npz')['adj_val_0']\n",
        "    adj_val_1 = np.load(f'/content/gdrive/My Drive/adjacency_features_{I}.npz')['adj_val_1']\n",
        "    adj_val_2 = np.load(f'/content/gdrive/My Drive/adjacency_features_{I}.npz')['adj_val_2']\n",
        "\n",
        "except Exception:\n",
        "    adj_trn_0, adj_trn_1, adj_trn_2, adj_val_0, adj_val_1, adj_val_2 = extract_adjacency_feature([trn_idx, val_idx])\n",
        "    np.savez_compressed(f'/content/gdrive/My Drive/adjacency_features_{I}', adj_trn_0=adj_trn_0, adj_trn_1=adj_trn_1, adj_trn_2=adj_trn_2, adj_val_0=adj_val_0, adj_val_1=adj_val_1, adj_val_2=adj_val_2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTX5Fn2Vy_nl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gsod = pd.read_csv('/content/gdrive/My Drive/flinders_chase_clean_5day.csv').values\n",
        "gsod = np.array(gsod, dtype='float')\n",
        "## normalize\n",
        "gsod = gsod/gsod.max(axis=0)\n",
        "\n",
        "num_trn_0, num_trn_1, num_trn_2 = gsod[:-2,:], gsod[1:-1,:], gsod[2:,:10]\n",
        "num_val_0, num_val_1, num_val_2 = gsod[:-2,:], gsod[1:-1,:], gsod[2:,:10]\n",
        "for i in range(len(trn_idx)-1):\n",
        "  num_trn_0 = np.concatenate([num_trn_0, gsod[:-2,:]])\n",
        "  num_trn_1 = np.concatenate([num_trn_1, gsod[1:-1,:]])\n",
        "  ### the last series should only have day_0 data!\n",
        "  num_trn_2 = np.concatenate([num_trn_2, gsod[2:,:10]])\n",
        "for i in range(len(val_idx)-1):\n",
        "  num_val_0 = np.concatenate([num_val_0, gsod[:-2,:]])\n",
        "  num_val_1 = np.concatenate([num_val_1, gsod[1:-1,:]])\n",
        "  ### the last series should only have day_0 data!\n",
        "  num_val_2 = np.concatenate([num_val_2, gsod[2:,:10]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6MmnTKPy_qQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_loss(y_true, y_pred, w=20):\n",
        "    crossentropy_loss = K.binary_crossentropy(y_true, y_pred)\n",
        "    weight  = (y_true*(w-1)) + 1\n",
        "    return crossentropy_loss*(weight)*(1/w)\n",
        "\n",
        "def f2_loss(y_true, y_pred, beta=2):\n",
        "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "    p = tp / (tp + fp + K.epsilon())\n",
        "    r = tp / (tp + fn + K.epsilon())\n",
        "    f_score = (1+beta**2) * p * r / ( (beta**2) * p + r + K.epsilon())\n",
        "    f_score = tf.where(tf.is_nan(f_score), tf.zeros_like(f_score), f_score)\n",
        "    return 1 - K.mean(f_score)\n",
        "\n",
        "def f4_loss(y_true, y_pred, beta=4):\n",
        "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "    p = tp / (tp + fp + K.epsilon())\n",
        "    r = tp / (tp + fn + K.epsilon())\n",
        "    f_score = (1+beta**2) * p * r / ( (beta**2) * p + r + K.epsilon())\n",
        "    f_score = tf.where(tf.is_nan(f_score), tf.zeros_like(f_score), f_score)\n",
        "    return 1 - K.mean(f_score)\n",
        "def custom_loss(y_true, y_pred, w=20):\n",
        "    crossentropy_loss = K.binary_crossentropy(y_true, y_pred)\n",
        "    weight  = (y_true*(w-1)) + 1\n",
        "    return crossentropy_loss*(weight)*(1/w)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUaojPZ1y_sw",
        "colab_type": "code",
        "outputId": "7fa45942-6d0b-4a93-b776-4597999df953",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "random_everything(seed=42)\n",
        "#model = Model(inputs=[img_0, img_1, img_2, num_0, num_1, num_2, adj_0, adj_1, adj_2], output=dense)\n",
        "\n",
        "model.compile(optimizer = Adam(lr=2e-5, decay=1e-6), \n",
        "              #loss=custom_loss,\n",
        "              loss=f4_loss,\n",
        "              metrics=['acc', recall_m, precision_m, f1_m, f2_m, f3_m, f4_m])\n",
        "\n",
        "ckpt = ModelCheckpoint(f\"/content/gdrive/My Drive/CNN_LSTM_{I}_final.hdf5\", monitor = \"val_f4_m\", save_best_only = True, mode = \"max\", save_weights_only=True)\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "\n",
        "history = model.fit([x_trn_0, x_trn_1, x_trn_2, num_trn_0, num_trn_1, num_trn_2, adj_trn_0, adj_trn_1, adj_trn_2], y_trn,\n",
        "                        validation_data=([x_val_0, x_val_1, x_val_2, num_val_0, num_val_1, num_val_2, adj_val_0, adj_val_1, adj_val_2], y_val),\n",
        "                        batch_size=24, epochs=100,\n",
        "                        callbacks=[es, ckpt, \n",
        "                                   keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-8 )\n",
        "                                   ]\n",
        "                        )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-8-eaf77e576dcc>:51: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 2120 samples, validate on 530 samples\n",
            "Epoch 1/100\n",
            "2120/2120 [==============================] - 95s 45ms/step - loss: 0.7449 - acc: 0.1660 - recall_m: 0.6368 - precision_m: 0.0498 - f1_m: 0.0907 - f2_m: 0.1813 - f3_m: 0.2761 - f4_m: 0.3554 - val_loss: 0.8546 - val_acc: 0.0226 - val_recall_m: 0.4113 - val_precision_m: 0.0226 - val_f1_m: 0.0418 - val_f2_m: 0.0881 - val_f3_m: 0.1426 - val_f4_m: 0.1933\n",
            "Epoch 2/100\n",
            "2120/2120 [==============================] - 71s 34ms/step - loss: 0.7292 - acc: 0.0495 - recall_m: 0.6566 - precision_m: 0.0491 - f1_m: 0.0897 - f2_m: 0.1804 - f3_m: 0.2760 - f4_m: 0.3568 - val_loss: 0.8343 - val_acc: 0.0226 - val_recall_m: 0.4113 - val_precision_m: 0.0226 - val_f1_m: 0.0418 - val_f2_m: 0.0881 - val_f3_m: 0.1426 - val_f4_m: 0.1933\n",
            "Epoch 3/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.6779 - acc: 0.0491 - recall_m: 0.7170 - precision_m: 0.0491 - f1_m: 0.0903 - f2_m: 0.1842 - f3_m: 0.2859 - f4_m: 0.3742 - val_loss: 0.8178 - val_acc: 0.0226 - val_recall_m: 0.4113 - val_precision_m: 0.0226 - val_f1_m: 0.0418 - val_f2_m: 0.0881 - val_f3_m: 0.1426 - val_f4_m: 0.1933\n",
            "Epoch 4/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.6605 - acc: 0.0491 - recall_m: 0.6717 - precision_m: 0.0491 - f1_m: 0.0901 - f2_m: 0.1825 - f3_m: 0.2809 - f4_m: 0.3643 - val_loss: 0.8058 - val_acc: 0.0226 - val_recall_m: 0.4113 - val_precision_m: 0.0226 - val_f1_m: 0.0418 - val_f2_m: 0.0881 - val_f3_m: 0.1426 - val_f4_m: 0.1933\n",
            "Epoch 5/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.6242 - acc: 0.0873 - recall_m: 0.6887 - precision_m: 0.0509 - f1_m: 0.0933 - f2_m: 0.1883 - f3_m: 0.2892 - f4_m: 0.3747 - val_loss: 0.7889 - val_acc: 0.2264 - val_recall_m: 0.4113 - val_precision_m: 0.0266 - val_f1_m: 0.0488 - val_f2_m: 0.1008 - val_f3_m: 0.1592 - val_f4_m: 0.2110\n",
            "Epoch 6/100\n",
            "2120/2120 [==============================] - 71s 34ms/step - loss: 0.6101 - acc: 0.3892 - recall_m: 0.6642 - precision_m: 0.0767 - f1_m: 0.1329 - f2_m: 0.2441 - f3_m: 0.3472 - f4_m: 0.4260 - val_loss: 0.7757 - val_acc: 0.3623 - val_recall_m: 0.4113 - val_precision_m: 0.0296 - val_f1_m: 0.0540 - val_f2_m: 0.1100 - val_f3_m: 0.1710 - val_f4_m: 0.2233\n",
            "Epoch 7/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.5728 - acc: 0.6057 - recall_m: 0.6679 - precision_m: 0.1167 - f1_m: 0.1910 - f2_m: 0.3199 - f3_m: 0.4231 - f4_m: 0.4933 - val_loss: 0.7508 - val_acc: 0.5585 - val_recall_m: 0.4113 - val_precision_m: 0.0399 - val_f1_m: 0.0712 - val_f2_m: 0.1373 - val_f3_m: 0.2023 - val_f4_m: 0.2534\n",
            "Epoch 8/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.4544 - acc: 0.8377 - recall_m: 0.7500 - precision_m: 0.2574 - f1_m: 0.3625 - f2_m: 0.5059 - f3_m: 0.5965 - f4_m: 0.6484 - val_loss: 0.7023 - val_acc: 0.8189 - val_recall_m: 0.3887 - val_precision_m: 0.1647 - val_f1_m: 0.1914 - val_f2_m: 0.2526 - val_f3_m: 0.2988 - val_f4_m: 0.3275\n",
            "Epoch 9/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.4961 - acc: 0.8580 - recall_m: 0.6204 - precision_m: 0.2641 - f1_m: 0.3500 - f2_m: 0.4593 - f3_m: 0.5228 - f4_m: 0.5572 - val_loss: 0.6810 - val_acc: 0.8868 - val_recall_m: 0.4113 - val_precision_m: 0.1675 - val_f1_m: 0.2317 - val_f2_m: 0.3086 - val_f3_m: 0.3508 - val_f4_m: 0.3728\n",
            "Epoch 10/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.4257 - acc: 0.9014 - recall_m: 0.6736 - precision_m: 0.3474 - f1_m: 0.4342 - f2_m: 0.5375 - f3_m: 0.5934 - f4_m: 0.6225 - val_loss: 0.6460 - val_acc: 0.9453 - val_recall_m: 0.4113 - val_precision_m: 0.2226 - val_f1_m: 0.2785 - val_f2_m: 0.3389 - val_f3_m: 0.3696 - val_f4_m: 0.3851\n",
            "Epoch 11/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.4517 - acc: 0.8882 - recall_m: 0.6349 - precision_m: 0.3204 - f1_m: 0.4032 - f2_m: 0.5013 - f3_m: 0.5555 - f4_m: 0.5840 - val_loss: 0.6354 - val_acc: 0.9377 - val_recall_m: 0.4113 - val_precision_m: 0.2604 - val_f1_m: 0.3011 - val_f2_m: 0.3486 - val_f3_m: 0.3744 - val_f4_m: 0.3879\n",
            "Epoch 12/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.3947 - acc: 0.9024 - recall_m: 0.6802 - precision_m: 0.3504 - f1_m: 0.4392 - f2_m: 0.5432 - f3_m: 0.5994 - f4_m: 0.6286 - val_loss: 0.6141 - val_acc: 0.9717 - val_recall_m: 0.4113 - val_precision_m: 0.2981 - val_f1_m: 0.3343 - val_f2_m: 0.3716 - val_f3_m: 0.3893 - val_f4_m: 0.3977\n",
            "Epoch 13/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.3957 - acc: 0.9222 - recall_m: 0.6623 - precision_m: 0.3938 - f1_m: 0.4676 - f2_m: 0.5549 - f3_m: 0.6004 - f4_m: 0.6234 - val_loss: 0.6648 - val_acc: 0.9340 - val_recall_m: 0.3887 - val_precision_m: 0.1683 - val_f1_m: 0.2136 - val_f2_m: 0.2782 - val_f3_m: 0.3197 - val_f4_m: 0.3434\n",
            "Epoch 14/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.4211 - acc: 0.9028 - recall_m: 0.6377 - precision_m: 0.3125 - f1_m: 0.3965 - f2_m: 0.4988 - f3_m: 0.5553 - f4_m: 0.5850 - val_loss: 0.6155 - val_acc: 0.9736 - val_recall_m: 0.4113 - val_precision_m: 0.2717 - val_f1_m: 0.3147 - val_f2_m: 0.3600 - val_f3_m: 0.3822 - val_f4_m: 0.3932\n",
            "Epoch 15/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.3536 - acc: 0.9123 - recall_m: 0.7019 - precision_m: 0.3732 - f1_m: 0.4663 - f2_m: 0.5718 - f3_m: 0.6266 - f4_m: 0.6544 - val_loss: 0.6283 - val_acc: 0.9755 - val_recall_m: 0.4113 - val_precision_m: 0.2717 - val_f1_m: 0.3147 - val_f2_m: 0.3600 - val_f3_m: 0.3822 - val_f4_m: 0.3932\n",
            "Epoch 16/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.4142 - acc: 0.9189 - recall_m: 0.6264 - precision_m: 0.3943 - f1_m: 0.4634 - f2_m: 0.5387 - f3_m: 0.5764 - f4_m: 0.5952 - val_loss: 0.6101 - val_acc: 0.9811 - val_recall_m: 0.4113 - val_precision_m: 0.2755 - val_f1_m: 0.3192 - val_f2_m: 0.3641 - val_f3_m: 0.3852 - val_f4_m: 0.3952\n",
            "Epoch 17/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.3418 - acc: 0.9387 - recall_m: 0.7034 - precision_m: 0.4496 - f1_m: 0.5281 - f2_m: 0.6111 - f3_m: 0.6515 - f4_m: 0.6712 - val_loss: 0.6097 - val_acc: 0.9830 - val_recall_m: 0.4113 - val_precision_m: 0.2981 - val_f1_m: 0.3343 - val_f2_m: 0.3716 - val_f3_m: 0.3893 - val_f4_m: 0.3977\n",
            "Epoch 18/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.3025 - acc: 0.9491 - recall_m: 0.7396 - precision_m: 0.5166 - f1_m: 0.5806 - f2_m: 0.6533 - f3_m: 0.6903 - f4_m: 0.7087 - val_loss: 0.6082 - val_acc: 0.9830 - val_recall_m: 0.4113 - val_precision_m: 0.2906 - val_f1_m: 0.3268 - val_f2_m: 0.3662 - val_f3_m: 0.3858 - val_f4_m: 0.3955\n",
            "Epoch 19/100\n",
            "2120/2120 [==============================] - 71s 34ms/step - loss: 0.3841 - acc: 0.9406 - recall_m: 0.6464 - precision_m: 0.4625 - f1_m: 0.5178 - f2_m: 0.5782 - f3_m: 0.6079 - f4_m: 0.6224 - val_loss: 0.6079 - val_acc: 0.9792 - val_recall_m: 0.4113 - val_precision_m: 0.3057 - val_f1_m: 0.3343 - val_f2_m: 0.3684 - val_f3_m: 0.3865 - val_f4_m: 0.3957\n",
            "Epoch 20/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.3886 - acc: 0.9340 - recall_m: 0.6406 - precision_m: 0.4508 - f1_m: 0.5051 - f2_m: 0.5678 - f3_m: 0.5994 - f4_m: 0.6149 - val_loss: 0.6057 - val_acc: 0.9792 - val_recall_m: 0.4113 - val_precision_m: 0.3057 - val_f1_m: 0.3404 - val_f2_m: 0.3751 - val_f3_m: 0.3912 - val_f4_m: 0.3989\n",
            "Epoch 21/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.3661 - acc: 0.9340 - recall_m: 0.6717 - precision_m: 0.4375 - f1_m: 0.5065 - f2_m: 0.5826 - f3_m: 0.6209 - f4_m: 0.6399 - val_loss: 0.6047 - val_acc: 0.9811 - val_recall_m: 0.4113 - val_precision_m: 0.3057 - val_f1_m: 0.3404 - val_f2_m: 0.3751 - val_f3_m: 0.3912 - val_f4_m: 0.3989\n",
            "Epoch 22/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.3201 - acc: 0.9453 - recall_m: 0.7198 - precision_m: 0.4985 - f1_m: 0.5594 - f2_m: 0.6308 - f3_m: 0.6682 - f4_m: 0.6873 - val_loss: 0.6189 - val_acc: 0.9792 - val_recall_m: 0.4113 - val_precision_m: 0.2830 - val_f1_m: 0.3192 - val_f2_m: 0.3608 - val_f3_m: 0.3824 - val_f4_m: 0.3932\n",
            "Epoch 23/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.3396 - acc: 0.9462 - recall_m: 0.6972 - precision_m: 0.4902 - f1_m: 0.5484 - f2_m: 0.6151 - f3_m: 0.6497 - f4_m: 0.6672 - val_loss: 0.6228 - val_acc: 0.9811 - val_recall_m: 0.4113 - val_precision_m: 0.2830 - val_f1_m: 0.3192 - val_f2_m: 0.3608 - val_f3_m: 0.3824 - val_f4_m: 0.3932\n",
            "Epoch 24/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.3465 - acc: 0.9401 - recall_m: 0.6915 - precision_m: 0.4481 - f1_m: 0.5185 - f2_m: 0.5982 - f3_m: 0.6384 - f4_m: 0.6583 - val_loss: 0.6346 - val_acc: 0.9811 - val_recall_m: 0.4113 - val_precision_m: 0.2906 - val_f1_m: 0.3268 - val_f2_m: 0.3662 - val_f3_m: 0.3858 - val_f4_m: 0.3955\n",
            "Epoch 25/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.3843 - acc: 0.9377 - recall_m: 0.6472 - precision_m: 0.4513 - f1_m: 0.5149 - f2_m: 0.5793 - f3_m: 0.6095 - f4_m: 0.6240 - val_loss: 0.6145 - val_acc: 0.9811 - val_recall_m: 0.4113 - val_precision_m: 0.2906 - val_f1_m: 0.3268 - val_f2_m: 0.3662 - val_f3_m: 0.3858 - val_f4_m: 0.3955\n",
            "Epoch 26/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.3471 - acc: 0.9486 - recall_m: 0.6849 - precision_m: 0.5057 - f1_m: 0.5576 - f2_m: 0.6158 - f3_m: 0.6454 - f4_m: 0.6601 - val_loss: 0.6120 - val_acc: 0.9811 - val_recall_m: 0.4113 - val_precision_m: 0.2906 - val_f1_m: 0.3268 - val_f2_m: 0.3662 - val_f3_m: 0.3858 - val_f4_m: 0.3955\n",
            "Epoch 27/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.3541 - acc: 0.9509 - recall_m: 0.6736 - precision_m: 0.4934 - f1_m: 0.5482 - f2_m: 0.6070 - f3_m: 0.6360 - f4_m: 0.6502 - val_loss: 0.6143 - val_acc: 0.9849 - val_recall_m: 0.4113 - val_precision_m: 0.3132 - val_f1_m: 0.3419 - val_f2_m: 0.3738 - val_f3_m: 0.3900 - val_f4_m: 0.3980\n",
            "Epoch 28/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.3513 - acc: 0.9575 - recall_m: 0.6717 - precision_m: 0.5208 - f1_m: 0.5694 - f2_m: 0.6192 - f3_m: 0.6426 - f4_m: 0.6537 - val_loss: 0.6138 - val_acc: 0.9849 - val_recall_m: 0.4113 - val_precision_m: 0.3132 - val_f1_m: 0.3419 - val_f2_m: 0.3738 - val_f3_m: 0.3900 - val_f4_m: 0.3980\n",
            "Epoch 29/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.3413 - acc: 0.9599 - recall_m: 0.6811 - precision_m: 0.5396 - f1_m: 0.5790 - f2_m: 0.6255 - f3_m: 0.6493 - f4_m: 0.6612 - val_loss: 0.6132 - val_acc: 0.9849 - val_recall_m: 0.4113 - val_precision_m: 0.3132 - val_f1_m: 0.3419 - val_f2_m: 0.3738 - val_f3_m: 0.3900 - val_f4_m: 0.3980\n",
            "Epoch 30/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.3528 - acc: 0.9561 - recall_m: 0.6691 - precision_m: 0.5396 - f1_m: 0.5759 - f2_m: 0.6191 - f3_m: 0.6408 - f4_m: 0.6514 - val_loss: 0.6112 - val_acc: 0.9830 - val_recall_m: 0.4113 - val_precision_m: 0.3132 - val_f1_m: 0.3419 - val_f2_m: 0.3738 - val_f3_m: 0.3900 - val_f4_m: 0.3980\n",
            "Epoch 31/100\n",
            "2120/2120 [==============================] - 71s 33ms/step - loss: 0.3681 - acc: 0.9590 - recall_m: 0.6528 - precision_m: 0.5047 - f1_m: 0.5514 - f2_m: 0.6003 - f3_m: 0.6236 - f4_m: 0.6348 - val_loss: 0.6097 - val_acc: 0.9849 - val_recall_m: 0.4113 - val_precision_m: 0.3132 - val_f1_m: 0.3419 - val_f2_m: 0.3738 - val_f3_m: 0.3900 - val_f4_m: 0.3980\n",
            "Epoch 00031: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1skCYp20eVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(f\"/content/gdrive/My Drive/CNN_LSTM_{I}_final.hdf5\")\n",
        "preds = model.predict([x_val_0, x_val_1, x_val_2, num_val_0, num_val_1, num_val_2, adj_val_0, adj_val_1, adj_val_2])\n",
        "np.save(f'/content/gdrive/My Drive/preds_{I}', preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43zirRHd0fhY",
        "colab_type": "code",
        "outputId": "a1630a79-8641-4129-b518-9e95984967c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, fbeta_score, cohen_kappa_score\n",
        "\n",
        "print(accuracy_score(y_val, preds.round().flatten()))\n",
        "print(f1_score(y_val, preds.round().flatten()))\n",
        "print(fbeta_score(y_val, preds.round().flatten(),2))\n",
        "print(fbeta_score(y_val, preds.round().flatten(),3))\n",
        "print(fbeta_score(y_val, preds.round().flatten(),4))\n",
        "print(cohen_kappa_score(y_val, preds.round().flatten()))\n",
        "print(recall_score(y_val, preds.round().flatten()))\n",
        "print(precision_score(y_val, preds.round().flatten()))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9792452830188679\n",
            "0.6857142857142856\n",
            "0.8450704225352113\n",
            "0.9160305343511451\n",
            "0.9488372093023256\n",
            "0.6760751194577175\n",
            "1.0\n",
            "0.5217391304347826\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6scVIv1GBKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_imgs_0 = np.load('/content/gdrive/My Drive/test_data.npz')['test_imgs_0']\n",
        "test_imgs_1 = np.load('/content/gdrive/My Drive/test_data.npz')['test_imgs_1']\n",
        "test_imgs_2 = np.load('/content/gdrive/My Drive/test_data.npz')['test_imgs_2']\n",
        "test_adj_0 = np.load('/content/gdrive/My Drive/test_data.npz')['test_adj_0']\n",
        "test_adj_1 = np.load('/content/gdrive/My Drive/test_data.npz')['test_adj_1']\n",
        "test_adj_2 = np.load('/content/gdrive/My Drive/test_data.npz')['test_adj_2']\n",
        "test_labs = np.load('/content/gdrive/My Drive/test_data.npz')['test_lab']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LORf2aKQI3Lo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_gsod = pd.read_csv('/content/gdrive/My Drive/test_gsod_final.csv').values\n",
        "test_gsod_0, test_gsod_1, test_gsod_2 = test_gsod[:-2,:], test_gsod[1:-1,:], test_gsod[2:,:10]\n",
        "for i in range(1,25):\n",
        "    test_gsod_0 = np.concatenate([test_gsod_0, test_gsod[:-2,:]])\n",
        "    test_gsod_1 = np.concatenate([test_gsod_1, test_gsod[1:-1,:]])\n",
        "    test_gsod_2 = np.concatenate([test_gsod_2, test_gsod[2:,:10]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74ZDxZo0I4a7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "I = 3\n",
        "model.load_weights(f\"/content/gdrive/My Drive/CNN_LSTM_{I}_final.hdf5\")\n",
        "test_preds = model.predict([test_imgs_0, test_imgs_1, test_imgs_2, test_gsod_0, test_gsod_1, test_gsod_2, test_adj_0, test_adj_1, test_adj_2])\n",
        "np.save(f'/content/gdrive/My Drive/test_preds_{I}', test_preds.flatten())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwuQ8OBCI54R",
        "colab_type": "code",
        "outputId": "6b4e7586-450d-415d-fd2f-ab502e444e49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, fbeta_score, cohen_kappa_score\n",
        "\n",
        "print(accuracy_score(test_labs, test_preds.round().flatten()))\n",
        "print(f1_score(test_labs, test_preds.round().flatten()))\n",
        "print(fbeta_score(test_labs, test_preds.round().flatten(),2))\n",
        "print(fbeta_score(test_labs, test_preds.round().flatten(),3))\n",
        "print(fbeta_score(test_labs, test_preds.round().flatten(),4))\n",
        "print(cohen_kappa_score(test_labs, test_preds.round().flatten()))\n",
        "print(recall_score(test_labs, test_preds.round().flatten()))\n",
        "print(precision_score(test_labs, test_preds.round().flatten()))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9333333333333333\n",
            "0.9295774647887325\n",
            "0.953757225433526\n",
            "0.9620991253644315\n",
            "0.9655765920826161\n",
            "0.866500533997864\n",
            "0.9705882352941176\n",
            "0.8918918918918919\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei9ThA5UI7Gt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}